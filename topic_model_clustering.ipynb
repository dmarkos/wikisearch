{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering documents using topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal in clustering is to group together similar documents creating a number of different groups. To judge the similarity of the documents it is common for each document to be represented by a vector of weights which are assigned to each word in the document. These weights in most cases are the <a src=https://en.wikipedia.org/wiki/Tf%E2%80%93idf>tf-idf</a> frequencies of the words. Thus, an NxM dimensional matrix is created where N is the number of documents and M the dimensions of the vector space (number of words in the dictionary of the document collection). The end result of clustering is a number of clusters with each document assigned to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another method of organizing a document collection is topic modeling. In topic modeling each word of the dictionary is associated with a probability of occurence in a topic and each topic is associated with a probability of occurence in a document. Each document is represented by a vector of the probabilities of each topic in it. This means that topic modeling results to a NxM matrix representation of the collection where N is the number of documents and M is the number of topics. Since we have a vector space representation of the documents we can use it for clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use <a src=http://radimrehurek.com/gensim/>Gensim</a> for topic modeling as it offers time and space efficient implementations of the topic modeling algorithms and it's free. It also supports parallelization although I don't make us of this feature here. With Gensim you can use either Latent Semantic Analysis (LSA) or Latent Dirichlet Allocation (LDA) to produce the topic vector space described above. We won't get into how these work now but you can find more information <a src=https://en.wikipedia.org/wiki/Latent_semantic_analysis>here</a> and <a src=https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>here</a>. In this implementation i will use LSA as it is faster thatn LDA. It is also less accurate but the goal of this notebook is a proof of concept. \n",
    "\n",
    "The data we are going to use are greek WikiPedia articles xml formatted and bz2 compressed. You can download them from <a src=https://dumps.wikimedia.org/elwiki/20170601/elwiki-20170601-pages-meta-history.xml.bz2>here</a>. Gensim can work directly on the compressed collection.\n",
    "\n",
    "First we need to create a Dictionary object, which is the dictionary of the document collection and associates each word to an id, and a MmCorpus object, which stores the corpus in a <a src=http://math.nist.gov/MatrixMarket/formats.html>Matrix Market</a> format. In a MmCorpus object each document can be represented by a vector of either integer count frequencies of it's word or tf-idf frequencies, but either way the resulting matrix is stored in the Matrix Market format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have saved the compressed WikiPedia XML file in a directory called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-01 14:55:56,120 : INFO : running /home/theovasi/anaconda3/lib/python3.6/site-packages/gensim/scripts/make_wikicorpus.py data/elwiki-20170720-pages-articles.xml.bz2 data/grwiki\n",
      "2017-08-01 14:55:56,323 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-08-01 14:56:25,444 : INFO : adding document #10000 to Dictionary(361468 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:56:46,820 : INFO : adding document #20000 to Dictionary(500714 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:57:05,578 : INFO : adding document #30000 to Dictionary(598622 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:57:24,443 : INFO : adding document #40000 to Dictionary(686151 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:57:42,056 : INFO : adding document #50000 to Dictionary(757946 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:58:01,081 : INFO : adding document #60000 to Dictionary(834243 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:58:18,331 : INFO : adding document #70000 to Dictionary(903189 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:58:38,320 : INFO : adding document #80000 to Dictionary(968007 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:58:56,657 : INFO : adding document #90000 to Dictionary(1032638 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:59:16,328 : INFO : adding document #100000 to Dictionary(1099346 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:59:36,327 : INFO : adding document #110000 to Dictionary(1158563 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 14:59:55,921 : INFO : adding document #120000 to Dictionary(1216908 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...)\n",
      "2017-08-01 15:00:01,163 : INFO : finished iterating over Wikipedia corpus of 122813 documents with 59080781 positions (total 282747 articles, 59624135 positions before pruning articles shorter than 50 words)\n",
      "2017-08-01 15:00:01,200 : INFO : built Dictionary(1252353 unique tokens: ['αθλητισμός', 'είναι', 'συστηματική', 'σωματική', 'καλλιέργεια']...) from 122813 documents (total 59080781 corpus positions)\n",
      "2017-08-01 15:00:02,988 : INFO : discarding 1153232 tokens: [('είναι', 89144), ('και', 118661), ('με', 104775), ('την', 104476), ('ως', 65718), ('σε', 88015), ('στο', 90990), ('ένας', 28946), ('οποίος', 24450), ('τη', 73154)]...\n",
      "2017-08-01 15:00:02,991 : INFO : keeping 99121 tokens which were in no less than 20 and no more than 12281 (=10.0%) documents\n",
      "2017-08-01 15:00:03,409 : INFO : resulting dictionary: Dictionary(99121 unique tokens: ['αθλητισμός', 'συστηματική', 'σωματική', 'καλλιέργεια', 'δράση']...)\n",
      "2017-08-01 15:00:03,511 : INFO : storing corpus in Matrix Market format to data/grwiki_bow.mm\n",
      "2017-08-01 15:00:03,544 : INFO : saving sparse matrix to data/grwiki_bow.mm\n",
      "2017-08-01 15:00:03,720 : INFO : PROGRESS: saving document #0\n",
      "2017-08-01 15:00:35,520 : INFO : PROGRESS: saving document #10000\n",
      "2017-08-01 15:00:59,077 : INFO : PROGRESS: saving document #20000\n",
      "2017-08-01 15:01:19,233 : INFO : PROGRESS: saving document #30000\n",
      "2017-08-01 15:01:39,448 : INFO : PROGRESS: saving document #40000\n",
      "2017-08-01 15:01:58,664 : INFO : PROGRESS: saving document #50000\n",
      "2017-08-01 15:02:19,289 : INFO : PROGRESS: saving document #60000\n",
      "2017-08-01 15:02:39,004 : INFO : PROGRESS: saving document #70000\n",
      "2017-08-01 15:03:04,299 : INFO : PROGRESS: saving document #80000\n",
      "2017-08-01 15:03:24,200 : INFO : PROGRESS: saving document #90000\n",
      "2017-08-01 15:03:46,027 : INFO : PROGRESS: saving document #100000\n",
      "2017-08-01 15:04:07,752 : INFO : PROGRESS: saving document #110000\n",
      "2017-08-01 15:04:29,058 : INFO : PROGRESS: saving document #120000\n",
      "2017-08-01 15:04:34,727 : INFO : finished iterating over Wikipedia corpus of 122813 documents with 59080781 positions (total 282747 articles, 59624135 positions before pruning articles shorter than 50 words)\n",
      "2017-08-01 15:04:34,765 : INFO : saved 122813x99121 matrix, density=0.172% (20926208/12173347373)\n",
      "2017-08-01 15:04:34,769 : INFO : saving MmCorpus index to data/grwiki_bow.mm.index\n",
      "2017-08-01 15:04:34,777 : INFO : saving dictionary mapping to data/grwiki_wordids.txt.bz2\n",
      "2017-08-01 15:04:36,774 : INFO : loaded corpus index from data/grwiki_bow.mm.index\n",
      "2017-08-01 15:04:36,775 : INFO : initializing corpus reader from data/grwiki_bow.mm\n",
      "2017-08-01 15:04:36,779 : INFO : accepted corpus with 122813 documents, 99121 features, 20926208 non-zero entries\n",
      "2017-08-01 15:04:36,783 : INFO : collecting document frequencies\n",
      "2017-08-01 15:04:36,789 : INFO : PROGRESS: processing document #0\n",
      "2017-08-01 15:04:48,723 : INFO : PROGRESS: processing document #10000\n",
      "2017-08-01 15:04:56,872 : INFO : PROGRESS: processing document #20000\n",
      "2017-08-01 15:05:04,013 : INFO : PROGRESS: processing document #30000\n",
      "2017-08-01 15:05:10,662 : INFO : PROGRESS: processing document #40000\n",
      "2017-08-01 15:05:16,828 : INFO : PROGRESS: processing document #50000\n",
      "2017-08-01 15:05:23,696 : INFO : PROGRESS: processing document #60000\n",
      "2017-08-01 15:05:29,950 : INFO : PROGRESS: processing document #70000\n",
      "2017-08-01 15:05:36,434 : INFO : PROGRESS: processing document #80000\n",
      "2017-08-01 15:05:42,250 : INFO : PROGRESS: processing document #90000\n",
      "2017-08-01 15:05:48,638 : INFO : PROGRESS: processing document #100000\n",
      "2017-08-01 15:05:54,826 : INFO : PROGRESS: processing document #110000\n",
      "2017-08-01 15:06:00,951 : INFO : PROGRESS: processing document #120000\n",
      "2017-08-01 15:06:02,641 : INFO : calculating IDF weights for 122813 documents and 99120 features (20926208 matrix non-zeros)\n",
      "2017-08-01 15:06:02,711 : INFO : saving TfidfModel object under data/grwiki.tfidf_model, separately None\n",
      "2017-08-01 15:06:02,774 : INFO : saved data/grwiki.tfidf_model\n",
      "2017-08-01 15:06:02,775 : INFO : storing corpus in Matrix Market format to data/grwiki_tfidf.mm\n",
      "2017-08-01 15:06:02,845 : INFO : saving sparse matrix to data/grwiki_tfidf.mm\n",
      "2017-08-01 15:06:02,849 : INFO : PROGRESS: saving document #0\n",
      "2017-08-01 15:06:27,633 : INFO : PROGRESS: saving document #10000\n",
      "2017-08-01 15:06:44,348 : INFO : PROGRESS: saving document #20000\n",
      "2017-08-01 15:07:00,110 : INFO : PROGRESS: saving document #30000\n",
      "2017-08-01 15:07:14,022 : INFO : PROGRESS: saving document #40000\n",
      "2017-08-01 15:07:26,996 : INFO : PROGRESS: saving document #50000\n",
      "2017-08-01 15:07:41,036 : INFO : PROGRESS: saving document #60000\n",
      "2017-08-01 15:07:54,004 : INFO : PROGRESS: saving document #70000\n",
      "2017-08-01 15:08:08,622 : INFO : PROGRESS: saving document #80000\n",
      "2017-08-01 15:08:20,712 : INFO : PROGRESS: saving document #90000\n",
      "2017-08-01 15:08:34,029 : INFO : PROGRESS: saving document #100000\n",
      "2017-08-01 15:08:46,987 : INFO : PROGRESS: saving document #110000\n",
      "2017-08-01 15:08:59,666 : INFO : PROGRESS: saving document #120000\n",
      "2017-08-01 15:09:03,165 : INFO : saved 122813x99121 matrix, density=0.172% (20926208/12173347373)\n",
      "2017-08-01 15:09:03,166 : INFO : saving MmCorpus index to data/grwiki_tfidf.mm.index\n",
      "2017-08-01 15:09:03,174 : INFO : finished running make_wikicorpus.py\n"
     ]
    }
   ],
   "source": [
    "%run -m gensim.scripts.make_wikicorpus data/elwiki-20170720-pages-articles.xml.bz2 data/grwiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above script takes the compressed XML file as its first argument. The second argument is the prefix of the output files. When run this script creates the dictionary and saves it in /data/grwiki_wordids.txt.bz2 and the tf-idf representation of the corpus saved in Matrix Market format in /data/grwiki_tfidf.mm. Now lets load these files and create the needed objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First unzip the dictionary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!bzip2 -dk data/grwiki_wordids.txt.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dictionary and MmCorpus objects by loading the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-02 14:37:42,150 : INFO : loaded corpus index from ../data/grwiki_tfidf.mm.index\n",
      "2017-08-02 14:37:42,151 : INFO : initializing corpus reader from ../data/grwiki_tfidf.mm\n",
      "2017-08-02 14:37:42,152 : INFO : accepted corpus with 122813 documents, 99121 features, 20926208 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "import logging, gensim, bz2\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "    level=logging.INFO) # Allow gensim to print additional info.\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary.load_from_text('../data/grwiki_wordids.txt')\n",
    "corpus = gensim.corpora.MmCorpus('../data/grwiki_tfidf.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the LSA of the Greek WikiPedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-02 14:37:44,835 : INFO : using serial LSI version on this node\n",
      "2017-08-02 14:37:44,836 : INFO : updating model with new documents\n",
      "2017-08-02 14:38:09,468 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:38:10,465 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:38:10,466 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:38:12,310 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:38:34,111 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:38:35,581 : INFO : computing the final decomposition\n",
      "2017-08-02 14:38:35,582 : INFO : keeping 100 factors (discarding 22.285% of energy spectrum)\n",
      "2017-08-02 14:38:35,825 : INFO : processed documents up to #20000\n",
      "2017-08-02 14:38:35,876 : INFO : topic #0(14.900): 0.274*\"έλληνας\" + 0.217*\"αμερικανός\" + 0.199*\"πολιτικός\" + 0.188*\"ηθοποιός\" + 0.145*\"συγγραφέας\" + 0.134*\"βασιλιάς\" + 0.131*\"γεννήσεις\" + 0.129*\"θάνατοι\" + 0.128*\"γρηγοριανό\" + 0.127*\"hμερολόγιο\"\n",
      "2017-08-02 14:38:35,879 : INFO : topic #1(11.223): 0.169*\"έλληνας\" + 0.161*\"αμερικανός\" + 0.128*\"ηθοποιός\" + 0.120*\"πολιτικός\" + 0.101*\"hμερολόγιο\" + 0.099*\"γρηγοριανό\" + 0.099*\"γεννήσεις\" + 0.097*\"θάνατοι\" + 0.085*\"συγγραφέας\" + 0.085*\"γάλλος\"\n",
      "2017-08-02 14:38:35,882 : INFO : topic #2(9.450): 0.247*\"έλληνας\" + 0.245*\"αμερικανός\" + -0.244*\"γεννήσεις\" + -0.236*\"θάνατοι\" + -0.230*\"hμερολόγιο\" + -0.228*\"τρέχουσα\" + -0.227*\"γρηγοριανό\" + 0.223*\"ηθοποιός\" + -0.192*\"σελίδα\" + -0.181*\"βασιλιάς\"\n",
      "2017-08-02 14:38:35,885 : INFO : topic #3(8.749): 0.551*\"ποδοσφαιριστές\" + 0.185*\"εθνική\" + 0.149*\"εθνικής\" + 0.147*\"πρωτάθλημα\" + 0.139*\"αεκ\" + 0.137*\"ελλάδος\" + 0.129*\"ελλάδας\" + 0.124*\"ολυμπιακού\" + 0.121*\"αγωνίστηκε\" + 0.115*\"ολυμπιακός\"\n",
      "2017-08-02 14:38:35,887 : INFO : topic #4(7.665): -0.399*\"δήμος\" + -0.206*\"δήμο\" + -0.202*\"κατοίκους\" + -0.197*\"χωριό\" + -0.181*\"νομού\" + -0.175*\"δήμου\" + -0.156*\"άγιος\" + -0.154*\"πληθυσμό\" + -0.121*\"χωριού\" + -0.110*\"απογραφή\"\n",
      "2017-08-02 14:38:52,882 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:38:53,590 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:38:53,591 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:38:54,878 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:39:12,064 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:39:14,102 : INFO : computing the final decomposition\n",
      "2017-08-02 14:39:14,104 : INFO : keeping 100 factors (discarding 20.653% of energy spectrum)\n",
      "2017-08-02 14:39:14,415 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:39:17,687 : INFO : keeping 100 factors (discarding 13.145% of energy spectrum)\n",
      "2017-08-02 14:39:18,061 : INFO : processed documents up to #40000\n",
      "2017-08-02 14:39:18,072 : INFO : topic #0(17.919): 0.162*\"ποδοσφαιριστές\" + 0.136*\"έλληνας\" + 0.109*\"δήμος\" + 0.101*\"πολιτικός\" + 0.095*\"αμερικανός\" + 0.088*\"ηθοποιός\" + 0.086*\"βασιλιάς\" + 0.085*\"χωριό\" + 0.079*\"px\" + 0.075*\"εθνική\"\n",
      "2017-08-02 14:39:18,077 : INFO : topic #1(14.465): -0.467*\"ποδοσφαιριστές\" + 0.285*\"δήμος\" + 0.173*\"δημοτικά\" + 0.171*\"διαμερίσματα\" + 0.164*\"νομού\" + 0.160*\"δήμο\" + 0.137*\"δήμου\" + 0.123*\"χωριό\" + 0.120*\"κατοίκους\" + -0.115*\"εθνική\"\n",
      "2017-08-02 14:39:18,086 : INFO : topic #2(14.083): 0.391*\"ποδοσφαιριστές\" + 0.260*\"δήμος\" + 0.160*\"δημοτικά\" + 0.158*\"διαμερίσματα\" + 0.143*\"νομού\" + 0.142*\"δήμο\" + -0.127*\"μυθολογίας\" + 0.119*\"δήμου\" + -0.114*\"έλληνας\" + -0.113*\"patsi\"\n",
      "2017-08-02 14:39:18,091 : INFO : topic #3(13.791): 0.264*\"μυθολογίας\" + 0.237*\"patsi\" + 0.237*\"garin\" + 0.235*\"επίτομο\" + 0.229*\"emmy\" + 0.228*\"ποδοσφαιριστές\" + 0.227*\"πάτση\" + 0.213*\"μυθολογία\" + 0.189*\"λεξικό\" + 0.175*\"οίκος\"\n",
      "2017-08-02 14:39:18,094 : INFO : topic #4(12.268): -0.219*\"δήμος\" + -0.192*\"ποδοσφαιριστές\" + -0.186*\"έλληνας\" + -0.162*\"δημοτικά\" + -0.160*\"διαμερίσματα\" + -0.156*\"αμερικανός\" + -0.126*\"πολιτικός\" + -0.126*\"ηθοποιός\" + -0.110*\"μυθολογίας\" + -0.109*\"patsi\"\n",
      "2017-08-02 14:39:34,123 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:39:34,799 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:39:34,800 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:39:36,066 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:39:57,164 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:39:59,375 : INFO : computing the final decomposition\n",
      "2017-08-02 14:39:59,376 : INFO : keeping 100 factors (discarding 19.989% of energy spectrum)\n",
      "2017-08-02 14:39:59,740 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:40:03,023 : INFO : keeping 100 factors (discarding 13.422% of energy spectrum)\n",
      "2017-08-02 14:40:03,473 : INFO : processed documents up to #60000\n",
      "2017-08-02 14:40:03,476 : INFO : topic #0(22.625): 0.209*\"εκτιμάται\" + 0.201*\"μέση\" + 0.194*\"αστεροειδών\" + 0.186*\"φασματικός\" + 0.184*\"παρατηρούσε\" + 0.184*\"άλβεδό\" + 0.181*\"αστεροειδής\" + 0.181*\"jpl\" + 0.180*\"διάμετρος\" + 0.180*\"τροχιά\"\n",
      "2017-08-02 14:40:03,484 : INFO : topic #1(20.654): 0.220*\"ποδοσφαιριστές\" + 0.106*\"έλληνας\" + 0.098*\"εθνική\" + 0.098*\"δήμος\" + 0.096*\"px\" + 0.092*\"χωριό\" + 0.082*\"πρωτάθλημα\" + 0.076*\"νομού\" + 0.074*\"εθνικής\" + 0.074*\"πολιτικός\"\n",
      "2017-08-02 14:40:03,491 : INFO : topic #2(17.180): -0.621*\"ποδοσφαιριστές\" + 0.148*\"δήμος\" + -0.146*\"εθνική\" + -0.126*\"πρωτάθλημα\" + -0.121*\"αγωνίστηκε\" + -0.120*\"κύπελλο\" + -0.119*\"γκολ\" + -0.114*\"εθνικής\" + 0.107*\"χωριό\" + 0.106*\"νομού\"\n",
      "2017-08-02 14:40:03,493 : INFO : topic #3(15.666): 0.334*\"δήμος\" + 0.219*\"νομού\" + 0.209*\"ποδοσφαιριστές\" + 0.189*\"δήμο\" + 0.181*\"δήμου\" + 0.173*\"χωριό\" + 0.168*\"διαμερίσματα\" + 0.166*\"δημοτικά\" + 0.142*\"κατοίκους\" + -0.131*\"έλληνας\"\n",
      "2017-08-02 14:40:03,497 : INFO : topic #4(14.061): -0.267*\"μυθολογίας\" + -0.237*\"patsi\" + -0.237*\"garin\" + -0.235*\"επίτομο\" + -0.231*\"μυθολογία\" + -0.229*\"emmy\" + -0.227*\"πάτση\" + -0.191*\"λεξικό\" + -0.178*\"οίκος\" + -0.171*\"ελληνικής\"\n",
      "2017-08-02 14:40:19,058 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:40:19,711 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:40:19,712 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:40:20,918 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:40:38,064 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:40:39,814 : INFO : computing the final decomposition\n",
      "2017-08-02 14:40:39,815 : INFO : keeping 100 factors (discarding 20.845% of energy spectrum)\n",
      "2017-08-02 14:40:40,003 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:40:42,307 : INFO : keeping 100 factors (discarding 13.038% of energy spectrum)\n",
      "2017-08-02 14:40:42,692 : INFO : processed documents up to #80000\n",
      "2017-08-02 14:40:42,695 : INFO : topic #0(30.988): 0.231*\"φυσικά\" + 0.217*\"αστεροειδών\" + 0.212*\"jpl\" + 0.209*\"κύριας\" + 0.209*\"java\" + 0.207*\"αστεροειδής\" + 0.207*\"τροχιά\" + 0.204*\"ηλιακό\" + 0.203*\"απόλυτο\" + 0.201*\"παρατηρούσε\"\n",
      "2017-08-02 14:40:42,699 : INFO : topic #1(23.591): 0.348*\"ποδοσφαιριστές\" + 0.138*\"px\" + 0.125*\"εθνική\" + 0.116*\"πρωτάθλημα\" + 0.098*\"εθνικής\" + 0.088*\"έλληνας\" + 0.083*\"κύπελλο\" + 0.079*\"αγώνες\" + 0.075*\"ελλάδας\" + 0.074*\"χωριό\"\n",
      "2017-08-02 14:40:42,704 : INFO : topic #2(20.042): -0.644*\"ποδοσφαιριστές\" + -0.113*\"εθνική\" + -0.103*\"γκολ\" + -0.100*\"εθνικής\" + -0.097*\"αγωνίστηκε\" + 0.096*\"δήμος\" + 0.096*\"χωριό\" + -0.095*\"πρωτάθλημα\" + -0.086*\"κύπελλο\" + -0.085*\"καριέρα\"\n",
      "2017-08-02 14:40:42,708 : INFO : topic #3(16.725): -0.304*\"δήμος\" + -0.260*\"ποδοσφαιριστές\" + 0.241*\"px\" + -0.219*\"νομού\" + -0.211*\"χωριό\" + -0.185*\"δήμο\" + -0.177*\"δήμου\" + -0.158*\"κατοίκους\" + -0.145*\"κοινότητα\" + -0.140*\"διαμερίσματα\"\n",
      "2017-08-02 14:40:42,711 : INFO : topic #4(16.405): 0.582*\"px\" + -0.296*\"ποδοσφαιριστές\" + 0.147*\"πρωτάθλημα\" + 0.139*\"παναθηναϊκός\" + 0.137*\"ολυμπιακός\" + 0.114*\"πανελλήνιος\" + 0.100*\"δήμος\" + 0.092*\"αγώνες\" + 0.088*\"πανιώνιος\" + -0.087*\"έλληνας\"\n",
      "2017-08-02 14:40:57,608 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:40:58,250 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:40:58,253 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:40:59,433 : INFO : orthonormalizing (99121, 200) action matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-02 14:41:16,372 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:41:17,543 : INFO : computing the final decomposition\n",
      "2017-08-02 14:41:17,544 : INFO : keeping 100 factors (discarding 22.932% of energy spectrum)\n",
      "2017-08-02 14:41:17,752 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:41:20,074 : INFO : keeping 100 factors (discarding 12.312% of energy spectrum)\n",
      "2017-08-02 14:41:20,377 : INFO : processed documents up to #100000\n",
      "2017-08-02 14:41:20,380 : INFO : topic #0(31.378): 0.232*\"φυσικά\" + 0.217*\"αστεροειδών\" + 0.212*\"jpl\" + 0.209*\"κύριας\" + 0.209*\"java\" + 0.207*\"αστεροειδής\" + 0.207*\"τροχιά\" + 0.203*\"ηλιακό\" + 0.202*\"απόλυτο\" + 0.201*\"ζώνης\"\n",
      "2017-08-02 14:41:20,385 : INFO : topic #1(26.171): 0.360*\"ποδοσφαιριστές\" + 0.138*\"εθνική\" + 0.135*\"πρωτάθλημα\" + 0.119*\"px\" + 0.106*\"κύπελλο\" + 0.102*\"εθνικής\" + 0.096*\"ποδοσφαίρου\" + 0.081*\"αγώνες\" + 0.080*\"έλληνας\" + 0.079*\"ομάδες\"\n",
      "2017-08-02 14:41:20,390 : INFO : topic #2(22.064): -0.590*\"ποδοσφαιριστές\" + -0.111*\"εθνική\" + -0.105*\"πρωτάθλημα\" + -0.101*\"κύπελλο\" + -0.095*\"γκολ\" + -0.094*\"ποδοσφαίρου\" + 0.094*\"χωριό\" + -0.092*\"αγωνίστηκε\" + -0.090*\"εθνικής\" + 0.082*\"δήμος\"\n",
      "2017-08-02 14:41:20,394 : INFO : topic #3(17.998): 0.266*\"δήμος\" + 0.233*\"χωριό\" + 0.217*\"νομού\" + 0.183*\"δήμο\" + 0.179*\"ποδοσφαιριστές\" + 0.169*\"δήμου\" + 0.161*\"κατοίκους\" + 0.148*\"κοινότητα\" + -0.145*\"κόμμα\" + 0.139*\"απογραφή\"\n",
      "2017-08-02 14:41:20,399 : INFO : topic #4(17.693): 0.500*\"px\" + -0.436*\"ποδοσφαιριστές\" + 0.191*\"πρωτάθλημα\" + 0.131*\"κύπελλο\" + 0.127*\"ολυμπιακός\" + 0.121*\"παναθηναϊκός\" + 0.120*\"ομάδες\" + 0.103*\"αγώνες\" + 0.101*\"ανδρών\" + 0.098*\"πανελλήνιος\"\n",
      "2017-08-02 14:41:35,860 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:41:36,493 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:41:36,494 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:41:37,686 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:41:55,365 : INFO : 2nd phase: running dense svd on (200, 20000) matrix\n",
      "2017-08-02 14:41:57,359 : INFO : computing the final decomposition\n",
      "2017-08-02 14:41:57,360 : INFO : keeping 100 factors (discarding 21.288% of energy spectrum)\n",
      "2017-08-02 14:41:57,635 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:42:00,399 : INFO : keeping 100 factors (discarding 10.843% of energy spectrum)\n",
      "2017-08-02 14:42:00,756 : INFO : processed documents up to #120000\n",
      "2017-08-02 14:42:00,759 : INFO : topic #0(31.663): 0.230*\"φυσικά\" + 0.215*\"αστεροειδών\" + 0.209*\"jpl\" + 0.208*\"κύριας\" + 0.206*\"java\" + 0.206*\"αστεροειδής\" + 0.206*\"τροχιά\" + 0.202*\"ηλιακό\" + 0.200*\"απόλυτο\" + 0.200*\"ζώνης\"\n",
      "2017-08-02 14:42:00,765 : INFO : topic #1(28.222): 0.315*\"ποδοσφαιριστές\" + 0.135*\"πρωτάθλημα\" + 0.131*\"εθνική\" + 0.127*\"px\" + 0.103*\"κύπελλο\" + 0.095*\"εθνικής\" + 0.087*\"ποδοσφαίρου\" + 0.084*\"αγώνες\" + 0.080*\"έλληνας\" + 0.080*\"ομάδες\"\n",
      "2017-08-02 14:42:00,773 : INFO : topic #2(23.604): -0.593*\"ποδοσφαιριστές\" + -0.123*\"πρωτάθλημα\" + -0.119*\"εθνική\" + -0.112*\"κύπελλο\" + -0.099*\"αγωνίστηκε\" + -0.098*\"ποδοσφαίρου\" + -0.094*\"γκολ\" + -0.093*\"εθνικής\" + 0.087*\"χωριό\" + -0.085*\"λιγκ\"\n",
      "2017-08-02 14:42:00,776 : INFO : topic #3(19.478): 0.338*\"px\" + -0.211*\"κόμμα\" + -0.177*\"ποδοσφαιριστές\" + -0.176*\"εκλογές\" + 0.176*\"δήμος\" + 0.173*\"χωριό\" + 0.145*\"νομού\" + -0.123*\"βουλευτές\" + 0.122*\"δήμο\" + 0.116*\"κατοίκους\"\n",
      "2017-08-02 14:42:00,779 : INFO : topic #4(19.382): 0.506*\"px\" + -0.412*\"ποδοσφαιριστές\" + -0.164*\"χωριό\" + -0.158*\"δήμος\" + 0.138*\"πρωτάθλημα\" + -0.134*\"νομού\" + -0.114*\"δήμο\" + -0.109*\"δήμου\" + -0.109*\"κατοίκους\" + -0.099*\"απογραφή\"\n",
      "2017-08-02 14:42:03,095 : INFO : preparing a new chunk of documents\n",
      "2017-08-02 14:42:03,191 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-08-02 14:42:03,192 : INFO : 1st phase: constructing (99121, 200) action matrix\n",
      "2017-08-02 14:42:03,370 : INFO : orthonormalizing (99121, 200) action matrix\n",
      "2017-08-02 14:42:19,973 : INFO : 2nd phase: running dense svd on (200, 2813) matrix\n",
      "2017-08-02 14:42:20,491 : INFO : computing the final decomposition\n",
      "2017-08-02 14:42:20,492 : INFO : keeping 100 factors (discarding 23.360% of energy spectrum)\n",
      "2017-08-02 14:42:20,803 : INFO : merging projections: (99121, 100) + (99121, 100)\n",
      "2017-08-02 14:42:23,336 : INFO : keeping 100 factors (discarding 3.616% of energy spectrum)\n",
      "2017-08-02 14:42:23,659 : INFO : processed documents up to #122813\n",
      "2017-08-02 14:42:23,662 : INFO : topic #0(31.676): 0.230*\"φυσικά\" + 0.214*\"αστεροειδών\" + 0.209*\"jpl\" + 0.207*\"κύριας\" + 0.206*\"java\" + 0.205*\"αστεροειδής\" + 0.205*\"τροχιά\" + 0.201*\"ηλιακό\" + 0.200*\"απόλυτο\" + 0.199*\"ζώνης\"\n",
      "2017-08-02 14:42:23,668 : INFO : topic #1(28.462): 0.305*\"ποδοσφαιριστές\" + 0.133*\"πρωτάθλημα\" + 0.129*\"εθνική\" + 0.124*\"px\" + 0.101*\"κύπελλο\" + 0.093*\"εθνικής\" + 0.086*\"ποδοσφαίρου\" + 0.083*\"αγώνες\" + 0.080*\"έλληνας\" + 0.079*\"κόμμα\"\n",
      "2017-08-02 14:42:23,674 : INFO : topic #2(23.764): -0.593*\"ποδοσφαιριστές\" + -0.127*\"πρωτάθλημα\" + -0.122*\"εθνική\" + -0.114*\"κύπελλο\" + -0.100*\"ποδοσφαίρου\" + -0.100*\"αγωνίστηκε\" + -0.095*\"γκολ\" + -0.095*\"εθνικής\" + 0.088*\"χωριό\" + -0.086*\"λιγκ\"\n",
      "2017-08-02 14:42:23,677 : INFO : topic #3(19.718): -0.229*\"κόμμα\" + 0.225*\"χωριό\" + 0.223*\"δήμος\" + -0.189*\"εκλογές\" + 0.186*\"νομού\" + 0.157*\"δήμο\" + 0.149*\"κατοίκους\" + 0.148*\"δήμου\" + 0.141*\"απογραφή\" + -0.134*\"βουλευτές\"\n",
      "2017-08-02 14:42:23,680 : INFO : topic #4(19.472): 0.584*\"px\" + -0.458*\"ποδοσφαιριστές\" + 0.170*\"πρωτάθλημα\" + 0.111*\"κύπελλο\" + 0.107*\"ομάδες\" + 0.103*\"ολυμπιακός\" + 0.103*\"αγώνες\" + 0.093*\"παναθηναϊκός\" + 0.090*\"ανδρών\" + -0.083*\"χωριό\"\n"
     ]
    }
   ],
   "source": [
    "lsi = gensim.models.lsimodel.LsiModel(corpus=corpus, id2word=dictionary, num_topics=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save LSI model for future use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-02 14:42:32,157 : INFO : saving Projection object under ../data/model.lsi.projection, separately None\n",
      "2017-08-02 14:42:32,940 : INFO : saved ../data/model.lsi.projection\n",
      "2017-08-02 14:42:32,942 : INFO : saving LsiModel object under ../data/model.lsi, separately None\n",
      "2017-08-02 14:42:32,943 : INFO : not storing attribute projection\n",
      "2017-08-02 14:42:32,944 : INFO : not storing attribute dispatcher\n",
      "2017-08-02 14:42:33,008 : INFO : saved ../data/model.lsi\n"
     ]
    }
   ],
   "source": [
    "lsi.save('../data/model.lsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a model that can transform a vector from the tf-idf vector space to the topic vector space. This model extracted 400 topics from the documents. The first 10 topics are printed below. Each topic is represented by its 10 most contributing words (negative or positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-08-02 14:42:36,742 : INFO : topic #0(31.676): 0.230*\"φυσικά\" + 0.214*\"αστεροειδών\" + 0.209*\"jpl\" + 0.207*\"κύριας\" + 0.206*\"java\" + 0.205*\"αστεροειδής\" + 0.205*\"τροχιά\" + 0.201*\"ηλιακό\" + 0.200*\"απόλυτο\" + 0.199*\"ζώνης\"\n",
      "2017-08-02 14:42:36,745 : INFO : topic #1(28.462): 0.305*\"ποδοσφαιριστές\" + 0.133*\"πρωτάθλημα\" + 0.129*\"εθνική\" + 0.124*\"px\" + 0.101*\"κύπελλο\" + 0.093*\"εθνικής\" + 0.086*\"ποδοσφαίρου\" + 0.083*\"αγώνες\" + 0.080*\"έλληνας\" + 0.079*\"κόμμα\"\n",
      "2017-08-02 14:42:36,748 : INFO : topic #2(23.764): -0.593*\"ποδοσφαιριστές\" + -0.127*\"πρωτάθλημα\" + -0.122*\"εθνική\" + -0.114*\"κύπελλο\" + -0.100*\"ποδοσφαίρου\" + -0.100*\"αγωνίστηκε\" + -0.095*\"γκολ\" + -0.095*\"εθνικής\" + 0.088*\"χωριό\" + -0.086*\"λιγκ\"\n",
      "2017-08-02 14:42:36,750 : INFO : topic #3(19.718): -0.229*\"κόμμα\" + 0.225*\"χωριό\" + 0.223*\"δήμος\" + -0.189*\"εκλογές\" + 0.186*\"νομού\" + 0.157*\"δήμο\" + 0.149*\"κατοίκους\" + 0.148*\"δήμου\" + 0.141*\"απογραφή\" + -0.134*\"βουλευτές\"\n",
      "2017-08-02 14:42:36,753 : INFO : topic #4(19.472): 0.584*\"px\" + -0.458*\"ποδοσφαιριστές\" + 0.170*\"πρωτάθλημα\" + 0.111*\"κύπελλο\" + 0.107*\"ομάδες\" + 0.103*\"ολυμπιακός\" + 0.103*\"αγώνες\" + 0.093*\"παναθηναϊκός\" + 0.090*\"ανδρών\" + -0.083*\"χωριό\"\n",
      "2017-08-02 14:42:36,758 : INFO : topic #5(18.707): -0.371*\"ταινίες\" + 0.294*\"κόμμα\" + -0.253*\"ταινία\" + 0.236*\"εκλογές\" + 0.170*\"βουλευτές\" + 0.154*\"βουλευτής\" + 0.117*\"υπουργός\" + 0.106*\"εξελέγη\" + -0.099*\"ταινίας\" + 0.095*\"δήμος\"\n",
      "2017-08-02 14:42:36,761 : INFO : topic #6(17.311): -0.712*\"px\" + -0.295*\"ποδοσφαιριστές\" + 0.219*\"ολυμπιονίκες\" + 0.174*\"αρχαίοι\" + 0.163*\"πρωτάθλημα\" + 0.134*\"ος\" + 0.112*\"κύπελλο\" + 0.109*\"ομάδες\" + 0.102*\"αγώνες\" + 0.097*\"αιώνας\"\n",
      "2017-08-02 14:42:36,765 : INFO : topic #7(16.905): 0.364*\"ταινίες\" + -0.316*\"ολυμπιονίκες\" + -0.276*\"αρχαίοι\" + 0.223*\"ταινία\" + -0.144*\"αιώνας\" + 0.142*\"κόμμα\" + -0.138*\"ποδοσφαιριστές\" + -0.121*\"px\" + -0.120*\"ος\" + 0.112*\"δήμος\"\n",
      "2017-08-02 14:42:36,768 : INFO : topic #8(16.430): 0.415*\"ολυμπιονίκες\" + 0.321*\"αρχαίοι\" + 0.309*\"ταινίες\" + 0.186*\"px\" + 0.178*\"ταινία\" + 0.171*\"αιώνας\" + 0.147*\"ος\" + 0.140*\"ολυμπιονίκης\" + 0.138*\"ους\" + 0.111*\"δήμος\"\n",
      "2017-08-02 14:42:36,772 : INFO : topic #9(15.274): 0.342*\"κόμμα\" + 0.206*\"άλμπουμ\" + 0.164*\"ολυμπιονίκες\" + 0.162*\"εκλογές\" + -0.147*\"έλληνας\" + 0.120*\"αρχαίοι\" + 0.118*\"έδρες\" + -0.109*\"πολιτικός\" + -0.093*\"αμερικανός\" + -0.091*\"βασιλιάς\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.230*\"φυσικά\" + 0.214*\"αστεροειδών\" + 0.209*\"jpl\" + 0.207*\"κύριας\" + 0.206*\"java\" + 0.205*\"αστεροειδής\" + 0.205*\"τροχιά\" + 0.201*\"ηλιακό\" + 0.200*\"απόλυτο\" + 0.199*\"ζώνης\"'),\n",
       " (1,\n",
       "  '0.305*\"ποδοσφαιριστές\" + 0.133*\"πρωτάθλημα\" + 0.129*\"εθνική\" + 0.124*\"px\" + 0.101*\"κύπελλο\" + 0.093*\"εθνικής\" + 0.086*\"ποδοσφαίρου\" + 0.083*\"αγώνες\" + 0.080*\"έλληνας\" + 0.079*\"κόμμα\"'),\n",
       " (2,\n",
       "  '-0.593*\"ποδοσφαιριστές\" + -0.127*\"πρωτάθλημα\" + -0.122*\"εθνική\" + -0.114*\"κύπελλο\" + -0.100*\"ποδοσφαίρου\" + -0.100*\"αγωνίστηκε\" + -0.095*\"γκολ\" + -0.095*\"εθνικής\" + 0.088*\"χωριό\" + -0.086*\"λιγκ\"'),\n",
       " (3,\n",
       "  '-0.229*\"κόμμα\" + 0.225*\"χωριό\" + 0.223*\"δήμος\" + -0.189*\"εκλογές\" + 0.186*\"νομού\" + 0.157*\"δήμο\" + 0.149*\"κατοίκους\" + 0.148*\"δήμου\" + 0.141*\"απογραφή\" + -0.134*\"βουλευτές\"'),\n",
       " (4,\n",
       "  '0.584*\"px\" + -0.458*\"ποδοσφαιριστές\" + 0.170*\"πρωτάθλημα\" + 0.111*\"κύπελλο\" + 0.107*\"ομάδες\" + 0.103*\"ολυμπιακός\" + 0.103*\"αγώνες\" + 0.093*\"παναθηναϊκός\" + 0.090*\"ανδρών\" + -0.083*\"χωριό\"'),\n",
       " (5,\n",
       "  '-0.371*\"ταινίες\" + 0.294*\"κόμμα\" + -0.253*\"ταινία\" + 0.236*\"εκλογές\" + 0.170*\"βουλευτές\" + 0.154*\"βουλευτής\" + 0.117*\"υπουργός\" + 0.106*\"εξελέγη\" + -0.099*\"ταινίας\" + 0.095*\"δήμος\"'),\n",
       " (6,\n",
       "  '-0.712*\"px\" + -0.295*\"ποδοσφαιριστές\" + 0.219*\"ολυμπιονίκες\" + 0.174*\"αρχαίοι\" + 0.163*\"πρωτάθλημα\" + 0.134*\"ος\" + 0.112*\"κύπελλο\" + 0.109*\"ομάδες\" + 0.102*\"αγώνες\" + 0.097*\"αιώνας\"'),\n",
       " (7,\n",
       "  '0.364*\"ταινίες\" + -0.316*\"ολυμπιονίκες\" + -0.276*\"αρχαίοι\" + 0.223*\"ταινία\" + -0.144*\"αιώνας\" + 0.142*\"κόμμα\" + -0.138*\"ποδοσφαιριστές\" + -0.121*\"px\" + -0.120*\"ος\" + 0.112*\"δήμος\"'),\n",
       " (8,\n",
       "  '0.415*\"ολυμπιονίκες\" + 0.321*\"αρχαίοι\" + 0.309*\"ταινίες\" + 0.186*\"px\" + 0.178*\"ταινία\" + 0.171*\"αιώνας\" + 0.147*\"ος\" + 0.140*\"ολυμπιονίκης\" + 0.138*\"ους\" + 0.111*\"δήμος\"'),\n",
       " (9,\n",
       "  '0.342*\"κόμμα\" + 0.206*\"άλμπουμ\" + 0.164*\"ολυμπιονίκες\" + 0.162*\"εκλογές\" + -0.147*\"έλληνας\" + 0.120*\"αρχαίοι\" + 0.118*\"έδρες\" + -0.109*\"πολιτικός\" + -0.093*\"αμερικανός\" + -0.091*\"βασιλιάς\"')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the LSI tranformation to the whole collection that is represented in\n",
    "the corpus object in tf-df form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_lsi = lsi[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have managed to create a topic space representation of the Greek \n",
    "WikiPedia and reduced teh dimensions of the vector space from NxM (N is\n",
    "the number of documents and M is sthe number of words in the dictionary) \n",
    "to Nx100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A document is represented in the new vector sapce like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.042989833735278704),\n",
       " (1, 0.105475082587364),\n",
       " (2, 0.049549003499134256),\n",
       " (3, 0.013062856119218934),\n",
       " (4, 0.02204411163481397),\n",
       " (5, -0.047807190516457036),\n",
       " (6, 0.0284289267668579),\n",
       " (7, -0.055413336050631423),\n",
       " (8, -0.029641930877875564),\n",
       " (9, 0.059438985055240236),\n",
       " (10, -0.054065284809135687),\n",
       " (11, -0.039249979659191643),\n",
       " (12, 0.049112866076368604),\n",
       " (13, 0.035616370087538853),\n",
       " (14, -0.02838093552936382),\n",
       " (15, 0.028172443444757729),\n",
       " (16, -0.0054790964251428941),\n",
       " (17, 0.010583760956673587),\n",
       " (18, -0.053756896374453959),\n",
       " (19, 0.041330807817491794),\n",
       " (20, -0.0083295155973422876),\n",
       " (21, -0.014025576836557125),\n",
       " (22, -0.010623162213868349),\n",
       " (23, 0.039771645652079864),\n",
       " (24, -0.027018406365771373),\n",
       " (25, 0.009627484256827995),\n",
       " (26, 0.034137094548587245),\n",
       " (27, 0.01792148482262676),\n",
       " (28, 0.032710251519061338),\n",
       " (29, -0.0083287278635223328),\n",
       " (30, 0.012102403734303963),\n",
       " (31, -0.038331377957459604),\n",
       " (32, 0.035679500035746908),\n",
       " (33, -0.027628653873314958),\n",
       " (34, -0.0086661559980908357),\n",
       " (35, 0.0055687497868131802),\n",
       " (36, 0.027082310298086013),\n",
       " (37, 0.028722463607950968),\n",
       " (38, -0.00058431606693259747),\n",
       " (39, 0.00529582082916748),\n",
       " (40, 0.0048327274897687388),\n",
       " (41, 0.029114911725576367),\n",
       " (42, 0.028133204116632018),\n",
       " (43, -0.001009653182552727),\n",
       " (44, -0.0052352851957410771),\n",
       " (45, -0.0074839469151265249),\n",
       " (46, 0.020175144640895336),\n",
       " (47, 0.0019364516487454164),\n",
       " (48, -0.009825648699264113),\n",
       " (49, -0.0038355186654085581),\n",
       " (50, 0.0023256822544631961),\n",
       " (51, 0.00046026092404682797),\n",
       " (52, 0.023956814785673436),\n",
       " (53, 0.01025891480795801),\n",
       " (54, 0.0082665440257827776),\n",
       " (55, 0.014709546857521886),\n",
       " (56, -0.0081615775238608294),\n",
       " (57, -0.014052784323411885),\n",
       " (58, 0.010329269723999798),\n",
       " (59, 0.0026249487801719745),\n",
       " (60, 0.0305577265562079),\n",
       " (61, -0.0043099971722128753),\n",
       " (62, -0.01508054955688146),\n",
       " (63, -0.0050300345525293409),\n",
       " (64, -0.0063271915961678662),\n",
       " (65, 0.010008536598893494),\n",
       " (66, 0.010710103756774943),\n",
       " (67, -0.00098013026318386734),\n",
       " (68, 0.0026837072622827155),\n",
       " (69, -0.0039406158688139892),\n",
       " (70, -0.0093925185599486264),\n",
       " (71, 0.0033245523625920767),\n",
       " (72, 0.010057079510124359),\n",
       " (73, -0.019852309242598669),\n",
       " (74, -0.011314915711088629),\n",
       " (75, 0.0024103423559106172),\n",
       " (76, -0.024808628323090786),\n",
       " (77, 0.017049594334513907),\n",
       " (78, 0.015385247004567636),\n",
       " (79, 0.019961907549371886),\n",
       " (80, 0.0023792923490727315),\n",
       " (81, 0.018026528654733216),\n",
       " (82, 0.0052659035263425006),\n",
       " (83, 0.01206931490536421),\n",
       " (84, -0.0059563444344320326),\n",
       " (85, 0.01476028390017114),\n",
       " (86, 0.004387376081008745),\n",
       " (87, 0.017087220668374762),\n",
       " (88, 0.0090183911932735783),\n",
       " (89, -0.0020030275761181143),\n",
       " (90, 0.0015496858574353411),\n",
       " (91, 0.022202127139612789),\n",
       " (92, 0.023466898888222888),\n",
       " (93, 0.0058202839608168131),\n",
       " (94, 0.0038641609325607887),\n",
       " (95, 0.0093698794354450561),\n",
       " (96, -0.013199909941299196),\n",
       " (97, 0.0060782702062719173),\n",
       " (98, -0.00043117665355644417),\n",
       " (99, 0.0048209845468060227)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_lsi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use scikit-learn for the clustering. Scikit's algorithms require for the vector space matrix to be in a sparse matrix format. Gensim \n",
    "provides a function to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsi_sparse = gensim.matutils.corpus2csc(corpus_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using <a src=https://en.wikipedia.org/wiki/K-means_clustering>k-means</a> to create 8 clusters without any refinements apart from a maximum iteration number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmodel = KMeans(n_clusters=8, max_iter=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Finally fit the k-means model on the documents x topic weights matrix we\n",
    "created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 14385.484\n",
      "Iteration  1, inertia 10073.993\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 14445.820\n",
      "Iteration  1, inertia 9936.316\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 13913.163\n",
      "Iteration  1, inertia 9410.579\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 14661.618\n",
      "Iteration  1, inertia 10349.191\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 14889.464\n",
      "Iteration  1, inertia 10273.376\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 14777.574\n",
      "Iteration  1, inertia 10305.512\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 15293.868\n",
      "Iteration  1, inertia 10746.607\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 13659.745\n",
      "Iteration  1, inertia 9158.406\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 15382.907\n",
      "Iteration  1, inertia 10804.790\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n",
      "Initialization complete\n",
      "Iteration  0, inertia 15056.058\n",
      "Iteration  1, inertia 9987.442\n",
      "Converged at iteration 1: center shift 0.000000e+00 within tolerance 1.012397e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=8, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmodel.fit(lsi_sparse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a trained k-means model, the next step is to find a way to\n",
    "visualize the result of the clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
